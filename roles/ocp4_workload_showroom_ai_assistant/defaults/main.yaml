---
# Connection to cluster to deploy to. Only set when deploying to a remote cluster.
# ocp4_workload_showroom_openshift_api_token: "{{ cluster_admin_agnosticd_sa_token }}"
# ocp4_workload_showroom_openshift_api_url: "{{ sandbox_openshift_api_url}}"

ocp4_workload_showroom_ai_assistant_name: "showroom-ai-assistant"
ocp4_workload_showroom_ai_assistant_namespace: "showroom-{{ guid | default('00000') }}"

# Per-container resource requests and limits

# Backend container
ocp4_workload_showroom_ai_assistant_backend_requests_cpu: 250m
ocp4_workload_showroom_ai_assistant_backend_requests_memory: 512Mi
ocp4_workload_showroom_ai_assistant_backend_limits_cpu: 1000m
ocp4_workload_showroom_ai_assistant_backend_limits_memory: 1Gi

# MCP server container
ocp4_workload_showroom_ai_assistant_mcp_server_requests_cpu: 100m
ocp4_workload_showroom_ai_assistant_mcp_server_requests_memory: 256Mi
ocp4_workload_showroom_ai_assistant_mcp_server_limits_cpu: 500m
ocp4_workload_showroom_ai_assistant_mcp_server_limits_memory: 512Mi

# LlamaStack container
ocp4_workload_showroom_ai_assistant_llamastack_requests_cpu: 500m
ocp4_workload_showroom_ai_assistant_llamastack_requests_memory: 2Gi
ocp4_workload_showroom_ai_assistant_llamastack_limits_cpu: "1"
ocp4_workload_showroom_ai_assistant_llamastack_limits_memory: 2Gi

# Vector loader init container
ocp4_workload_showroom_ai_assistant_vector_loader_requests_cpu: 200m
ocp4_workload_showroom_ai_assistant_vector_loader_requests_memory: 512Mi
ocp4_workload_showroom_ai_assistant_vector_loader_limits_cpu: 500m
ocp4_workload_showroom_ai_assistant_vector_loader_limits_memory: 1Gi

# Storage configuration
ocp4_workload_showroom_ai_assistant_llamastack_storage: 10Gi
ocp4_workload_showroom_ai_assistant_hfcache_storage: 10Gi

# Images for the AI assistant
ocp4_workload_showroom_ai_assistant_image: quay.io/jfalkner1/showroom-ai-assistant:latest
ocp4_workload_showroom_ai_assistant_rag_image: quay.io/jfalkner1/showroom-ai-assistant-vectors:latest
ocp4_workload_showroom_ai_assistant_mcp_kube_image: docker.io/node:20
ocp4_workload_showroom_ai_assistant_lls_image: docker.io/llamastack/distribution-starter:0.3.2


ocp4_workload_showroom_ai_assistant_mcp_kube_npm_package: kubernetes-mcp-server@latest

# Secret values (API keys and credentials)
ocp4_workload_showroom_ai_assistant_vllm_api_token: "PLACEHOLDER_VLLM_API_TOKEN_REPLACE_ME"
ocp4_workload_showroom_ai_assistant_vllm_url: ""
ocp4_workload_showroom_ai_assistant_vllm_max_tokens: ""
ocp4_workload_showroom_ai_assistant_vllm_tls_verify: ""

# Enable passthrough of agnosticd_passthrough_user_data to individual users
ocp4_workload_showroom_passthrough_user_data: false
